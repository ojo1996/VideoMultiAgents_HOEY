# agent_systems/Math_agent/Main.py
from __future__ import annotations

import argparse
import os
import re
import uuid
from typing import Optional

from .Tools import (
    LLMConfig,
    call_llm,
    run_bash,
    new_trajectory,
    record_action,
    save_trajectory,
    MATH_SYSTEM_PROMPT,
    FINALIZE_MATH_PROMPT,
)

BASH_BLOCK = re.compile(r"```bash\s*(.*?)```", re.S | re.I)

def extract_bash_command(text: str) -> Optional[str]:
    if not text:
        return None
    m = BASH_BLOCK.search(text)
    if not m:
        return None
    cmd = m.group(1).strip()
    cmd = re.sub(r"```$", "", cmd).strip()
    return cmd or None

def run_single_step(question: str, cfg: LLMConfig, trajectory, yolo: bool = True) -> str:
    user = f"Question:\n{question}\n\nFollow the output rules exactly."
    assistant = call_llm(MATH_SYSTEM_PROMPT, user, cfg=cfg)
    record_action(trajectory, "reason", {"prompt": user}, assistant)

    cmd = extract_bash_command(assistant)
    if not cmd:
        record_action(trajectory, "validator", {"error": "no_bash_block"}, "")
        return "No command extracted."

    rc, out, err = run_bash(cmd)
    record_action(
        trajectory, "bash",
        {"command": cmd},
        {"returncode": rc, "stdout": out, "stderr": err},
    )
    trajectory.setdefault("metadata", {}).setdefault("executed_cmds", []).append(cmd)
    return out if out else (err or f"(returncode={rc})")

def finalize_answer(latest_output: str, cfg: LLMConfig, trajectory) -> str:
    user = f"Latest command output:\n```\n{latest_output}\n```"
    ans = call_llm(FINALIZE_MATH_PROMPT, user, cfg=cfg)
    record_action(trajectory, "finalize", {"context": user}, ans)
    return ans.strip()

def main():
    ap = argparse.ArgumentParser(description="Math agent using OpenAI LLM and trajectory logging.")
    ap.add_argument("--question", "-q", required=True, help="Math question (string).")
    ap.add_argument("--task_id", default=None, help="Optional task id; autogenerated if omitted.")
    ap.add_argument("--out", "-o", default="runs/math_llm.traj.json", help="Where to write the trajectory JSON.")
    ap.add_argument("--steps", type=int, default=1, help="LLM->bash iterations (default: 1).")
    args = ap.parse_args()

    cfg = LLMConfig()
    task_id = args.task_id or f"math-{uuid.uuid4().hex[:8]}"
    traj = new_trajectory(task_id=task_id, domain="math")
    traj["question"] = args.question

    latest = ""
    for _ in range(max(1, args.steps)):
        latest = run_single_step(args.question, cfg, traj, yolo=True)

    final = finalize_answer(latest, cfg, traj)
    traj["final_answer"] = final

    out_path = os.path.expanduser(os.path.expandvars(args.out))
    save_trajectory(traj, out_path)
    print(f"[ok] saved trajectory -> {out_path}")

if __name__ == "__main__":
    main()